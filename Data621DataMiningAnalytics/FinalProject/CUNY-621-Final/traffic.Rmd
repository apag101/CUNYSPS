---
title: "Traffic Predictions"
subtitle: "Data 621 Final"
institute: "CUNY SPS"
author: "Tommy Jenkins, Violeta Stoyanova, Todd Weigel, Peter Kowalchuk, Eleanor R-Secoquian,
  Anthony Pagan"
date: "2019/12/04"
output:
  prettydoc::html_pretty:
    toc: true
    fig_width: 7
    fig_height: 4.5 
    theme: tactile 
    highlight: tango
--- 

```{r message=FALSE, warning=FALSE, include=FALSE}
#list.of.packages <- c("alluvial","caret","caret","corrplot","corrplot","data.table","dplyr","faraway","forcats","geosph#ere","ggplot2","ggplot2","ggplot2","grid","gridExtra","jtools","kableExtra","knitr","leaflet","leaflet.extras","leaps",#"lubridate","maps","MASS","mice","naniar","pander","patchwork","prettydoc","pROC","psych","RColorBrewer","readr","resha#pe2","scales","stringr","tibble","tidyr","tidyverse","xgboost","widgetframe","Rcpp")
#new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
#if(length(new.packages)) install.packages(new.packages)
```

```{r message=FALSE, warning=FALSE, include=FALSE}
require(knitr)
knitr::opts_chunk$set(echo = FALSE, warning = FALSE,fig.align='center')

library(faraway)
library(MASS)
library(psych)
library(pROC)
library(corrplot)
library(jtools)
library(mice)
library('corrr')
library(kableExtra)
library(gridExtra)
library(pander)
library(zoo)
library(lmtest)
library(corrr)
library(broom)

#devtools::install_github("thomasp85/patchwork")
library(patchwork)
library(tidyverse)
library(ggplot2)
library(ggplot2)
library(reshape2)
library(leaps)
library(caret)
library(naniar)
library('ggplot2') # visualisation
library('scales') # visualisation
library('grid') # visualisation
library('RColorBrewer') # visualisation
library('corrplot') # visualisation
library('alluvial') # visualisation
library('dplyr') # data manipulation
library('readr') # input/output
library('data.table') # data manipulation
library('tibble') # data wrangling
library('tidyr') # data wrangling
library('stringr') # string manipulation
library('forcats') # factor manipulation
library('lubridate') # date and time
library('geosphere') # geospatial locations
library('leaflet') # maps
library('leaflet.extras') # maps
library('maps') # maps
library('xgboost') # modelling
library('caret') # modelling
library('widgetframe') #visualizaiton
library('grid')
library('gridExtra')
```


## Utility functions


```{r message=TRUE, warning=TRUE}
# Define multiple plot function
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#

multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])
  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
```
From [R Cookbooks](http://www.cookbook-r.com/Graphs/Multiple_graphs_on_one_page_(ggplot2)/) to create multi-panel plots.


```{r message=FALSE, warning=FALSE}
var_stats<- function(df){ 
  wt<-data.frame(columns=colnames(df))
  wt$na_count <- sapply(df, function(y) sum(is.na(y)))
  wt$neg_count <- sapply(df, function(y) sum(y<0))
  wt$zero_count <- sapply(df, function(y) sum(as.integer(y)==0))
  wt$unique_count <- sapply(df, function(y) sum(n_distinct(y)))
  print(wt)
  return(wt)
}
```

## OVERVIEW

In this competition, Kaggle is challenging you to build a model that predicts the total ride duration of taxi trips in New York City. Your primary dataset is one released by the NYC Taxi and Limousine Commission, which includes pickup time, geo-coordinates, number of passengers, and several other variables.

The competition dataset is based on the 2016 NYC Yellow Cab trip record data made available in Big Query on Google Cloud Platform. The data was originally published by the NYC Taxi and Limousine Commission (TLC). The data was sampled and cleaned for the purposes of this playground competition. Based on individual trip attributes, participants should predict the duration of each trip in the test set.

**File descriptions**

* train.csv - the training set (contains 1458644 trip records)
* test.csv - the testing set (contains 625134 trip records)
* sample_submission.csv - a sample submission file in the correct format
https://www.kaggle.com/c/6960/download-all



**Data fields**
```{r echo=FALSE, message=FALSE, warning=FALSE} 
rows <- c("id","vendor_id","pickup_datetime","dropoff_datetime","passenger_count","pickup_longitude","pickup_latitude",
"dropoff_longitude","dropoff_latitude","store_and_fwd_flag","trip_duration")

def <- c("a unique identifier for each trip",
"a code indicating the provider associated with the trip record",
"date and time when the meter was engaged",
"date and time when the meter was disengaged",
"the number of passengers in the vehicle (driver entered value)",
"the longitude where the meter was engaged",
"the latitude where the meter was engaged",
"the longitude where the meter was disengaged",
"the latitude where the meter was disengaged",
"This flag indicates whether the trip record was held in vehicle memory before sending to the vendor because the vehicle did not have a connection to the server: Y=store and forward; N=not a store and forward trip",
"duration of the trip in seconds")

kable(cbind(rows, def), col.names = c("Variable Name", "Definition")) %>% kable_styling()
```

## Objective: 

The purpose of this project is to build various models in an attempt to predict the trip duration of yellow taxis in New York City. 

Using the techniques we've learned in the class, like classification, model diagnostics and transformation, we will explore data to find new patterns. And just like what is required in the Kaggle contest, we will try to predict the duration of each trip in the test set. We will build multiple linear regression modeling and then summary to interpret the results. We’ll further analyze the results by adding discrimination in the model and then assess the discrimination with ROC curve.


vvvv REWRITE vvv


# DATA EXPLORATION

## Load data


```{r message=FALSE, warning=FALSE} 
train <- as_tibble(fread('data/train.csv'))
test <- as_tibble(fread('data/test.csv'))
sample_submit <- as_tibble(fread('data/sample_submission.csv'))
```


### View Data
```{r message=FALSE, warning=FALSE}
#str(train)
glimpse(train)
#summary(train)
#describe(train) 
```


## Data Summary 
 
```{r message=FALSE, warning=FALSE}
names(train)
names(test)
#glimpse(test)

#   
vars_to_add <- train[!names(train) %in% names(test)]

 #vvvvv
## Combining train and test
 
combine <- rbind(train %>% mutate(dset = "train"), 
                     test %>% mutate(dset = "test",
                                     dropoff_datetime = NA,
                                     trip_duration = NA))
```


```{r message=FALSE, warning=FALSE}
combine <- combine %>% mutate(dset = factor(dset))
glimpse(combine)
summary(combine)
```

### Missing values
```{r message=FALSE, warning=FALSE}
var_stats(combine) 
gg_miss_upset(combine)
summary(complete.cases(combine))
```

#Data Preparation

## Reformating features

For our following analysis, we will turn the data and time from characters into *date* objects. We also recode *vendor\_id* as a factor. This makes it easier to visualise relationships that involve these features.

```{r message=FALSE, warning=FALSE}
train <- train %>%
  mutate(pickup_datetime = ymd_hms(pickup_datetime),
         dropoff_datetime = ymd_hms(dropoff_datetime),
         vendor_id = factor(vendor_id),
         passenger_count = factor(passenger_count))
```


# Visualizations 

```{r  fig.align = 'default', warning = FALSE, fig.cap ="Fig. 2", out.width="100%"}
#ggplot(combine, aes(trip_duration)) +
#  geom__histogram(aes(y = ..density..) 

attach(train)
boxplot(by(log(train$trip_duration),train$store_and_fwd_flag,summary),col=c("red","blue"),xlab="Store and Forward Flag", ylab="Trip Duration")
by(log(train$trip_duration),train$store_and_fwd_flag,summary)

#plot(trip_duration ~ dropoff_longitude,pch  = 20,cex  = 2,col  = "grey")

train[sapply(train, function(x) is.numeric(x) && !is.na(x))] %>% 
  gather() %>% 
  ggplot(aes(value), main="") +
  facet_wrap(~ key, scales = "free") +
  geom_histogram()

```

## Trip duration vs pickup and dropoff datetime and location using 20% of sampled data

```{r message=FALSE, warning=FALSE}
sub_train = train%>%sample_frac(.2)
attach(sub_train)
g1<-ggplot(sub_train, aes(x=I(pickup_latitude*pickup_longitude), y=log(trip_duration), color = store_and_fwd_flag)) +geom_point() +stat_smooth(method="glm", se=TRUE)
g2<-ggplot(sub_train, aes(x=I(dropoff_latitude*dropoff_longitude), y=log(trip_duration), color = store_and_fwd_flag)) +geom_point() +stat_smooth(method="glm", se=TRUE)
g3<-ggplot(sub_train, aes(x=pickup_datetime, y=log(trip_duration), color = store_and_fwd_flag)) +geom_point() +stat_smooth(method="glm", se=TRUE)
g4<-ggplot(sub_train, aes(x=dropoff_datetime, y=log(trip_duration), color = store_and_fwd_flag)) +geom_point() +stat_smooth(method="glm", se=TRUE)
grid.arrange(g1, g2, g3, g4, ncol = 2)

g1<-ggplot(sub_train, aes(x=I(pickup_latitude*pickup_longitude), y=log(trip_duration), color = vendor_id)) +geom_point() +stat_smooth(method="glm", se=TRUE)
g2<-ggplot(sub_train, aes(x=I(dropoff_latitude*dropoff_longitude), y=log(trip_duration), color = vendor_id)) +geom_point() +stat_smooth(method="glm", se=TRUE)
g3<-ggplot(sub_train, aes(x=pickup_datetime, y=log(trip_duration), color = vendor_id)) +geom_point() +stat_smooth(method="glm", se=TRUE)
g4<-ggplot(sub_train, aes(x=dropoff_datetime, y=log(trip_duration), color = vendor_id)) +geom_point() +stat_smooth(method="glm", se=TRUE)
grid.arrange(g1, g2, g3, g4, ncol = 2)


pairs(sub_train[sapply(sub_train, function(x) is.numeric(x))], col = "dodgerblue")


ssub_train<-sub_train[sapply(sub_train, function(x) is.numeric(x) && !is.na(x))]

ssub_train %>% 
  correlate() %>% 
  network_plot(min_cor = .2)

```

## More visualizations

```{r fig.align='default', fig.cap="Fig. 2", message=FALSE, warning=FALSE, out.width="100%"}
#log(sub_train$trip_duration) %>% as.double() %>% boxplot()
#bins
#scale_x_log10() +
#scale_y_sqrt()
attach(sub_train)
boxplot(log(trip_duration) ~ as.factor(passenger_count),  
     xlab   = "..",
     ylab   = "trip_duration",
     main   = "trip_duration vs ..",
     pch    = 20,
     cex    = 2,
     col    = "darkorange",
     border = "dodgerblue")

```


```{r fig.align='default', fig.cap="Fig. 6", message=FALSE, warning=FALSE, out.width="100%"}
p1 <- sub_train %>%
  filter(pickup_longitude > -74.05 & pickup_longitude < -73.7) %>%
  ggplot(aes(pickup_longitude)) +
  geom_histogram(fill = "red", bins = 40)

p2 <- sub_train %>%
  filter(dropoff_longitude > -74.05 & dropoff_longitude < -73.7) %>%
  ggplot(aes(dropoff_longitude)) +
  geom_histogram(fill = "blue", bins = 40)

p3 <- sub_train %>%
  filter(pickup_latitude > 40.6 & pickup_latitude < 40.9) %>%
  ggplot(aes(pickup_latitude)) +
  geom_histogram(fill = "red", bins = 40)

p4 <- sub_train %>%
  filter(dropoff_latitude > 40.6 & dropoff_latitude < 40.9) %>%
  ggplot(aes(dropoff_latitude)) +
  geom_histogram(fill = "blue", bins = 40)

layout <- matrix(c(1,2,3,4),2,2,byrow=FALSE)
multiplot(p1, p2, p3, p4, layout=layout)
p1 <- 1; p2 <- 1; p3 <- 1; p4 <- 1
```


```{r message=FALSE, warning=FALSE}
#jfk_coord <- tibble(lon = -73.778889, lat = 40.639722)

#la_guardia_coord <- tibble(lon = -73.872611, lat = 40.77725)


#train$jfk_dist_pick <- distCosine(pick_coord, jfk_coord)

#train$jfk_dist_drop <- distCosine(drop_coord, jfk_coord)

#train$lg_dist_pick <- distCosine(pick_coord, la_guardia_coord)

#train$lg_dist_drop <- distCosine(drop_coord, la_guardia_coord)



pick_coord <- sub_train %>% select(pickup_longitude, pickup_latitude)

drop_coord <- sub_train %>% select(dropoff_longitude, dropoff_latitude)

sub_train$dist <- distCosine(pick_coord, drop_coord)

#train$bearing = bearing(pick_coord, drop_coord)




sub_train <- sub_train %>%

  mutate(speed = dist/trip_duration*3.6,

         date = date(pickup_datetime),

         month = month(pickup_datetime, label = TRUE),

         wday = wday(pickup_datetime, label = TRUE),

         wday = fct_relevel(wday, c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun")),

         hour = hour(pickup_datetime),

         work = (hour %in% seq(8,18)) & (wday %in% c("Mon","Tue","Wed","Thu","Fri")),

 #        jfk_trip = (jfk_dist_pick < 2e3) | (jfk_dist_drop < 2e3),

 #       lg_trip = (lg_dist_pick < 2e3) | (lg_dist_drop < 2e3),

 #        blizzard = !( (date < ymd("2016-01-22") | (date > ymd("2016-01-29"))) )

         )

```


```{r message=FALSE, warning=FALSE}

sub_train <- sub_train %>%

  filter(trip_duration < 22*3600,

         dist > 0 | (near(dist, 0) & trip_duration < 60),

#         jfk_dist_pick < 3e5 & jfk_dist_drop < 3e5,

         trip_duration > 10,

         speed < 100)

```


```{r fig.align='default', fig.cap="Fig. 30a", fig.height=6, warning=FALSE, out.width="100%"}

sub_train %>%

  select(-id, -pickup_datetime, -dropoff_datetime, -date) %>% #-jfk_dist_pick,

 #        -jfk_dist_drop, -lg_dist_pick, -lg_dist_drop, -date) %>%

  mutate(passenger_count = as.integer(passenger_count),

         vendor_id = as.integer(vendor_id),

         store_and_fwd_flag = as.integer(as.factor(store_and_fwd_flag)),

 #        jfk_trip = as.integer(jfk_trip),

         wday = as.integer(wday),

         month = as.integer(month),

         work = as.integer(work))%>%

 #        lg_trip = as.integer(lg_trip),

 #        blizzard = as.integer(blizzard),

 #        has_snow = as.integer(has_snow),

  #       has_rain = as.integer(has_rain)) %>%
#
  select(trip_duration, speed, everything()) %>%

  cor(use="complete.obs", method = "spearman") %>%

  corrplot(type="lower", method="circle", diag=FALSE)

```

# An excursion into classification

```{r  fig.align = 'default', warning = FALSE, fig.cap ="Fig. 31", out.width="100%"}

train_group <- sub_train %>%

  mutate(tgroup = case_when(trip_duration < 3e2 ~ "fast",

                            trip_duration >= 3e2 & trip_duration <= 1.6e3 ~ "mid",

                            trip_duration > 1.6e3 ~ "slow"))



train_group %>%

  ggplot(aes(trip_duration, fill = tgroup)) +

  geom_histogram(bins = 300) +

  scale_x_log10() +

  scale_y_sqrt()

```


```{r fig.align = 'default', warning = FALSE, fig.cap ="Fig. 32", out.width="100%"}

train_group <- train_group %>%

  filter(tgroup != "mid")



p1 <- train_group %>%

  ggplot(aes(wday, fill = tgroup)) +

  geom_bar(position = "fill") +

  theme(legend.position = "none")

  

p2 <- train_group %>%

  ggplot(aes(month, fill = tgroup)) +

  geom_bar(position = "fill") +

  theme(legend.position = "none")



p3 <- train_group %>%

  ggplot(aes(hour, fill = tgroup)) +

  geom_bar(position = "fill")
 
p7 <- train_group %>%

  ggplot(aes(work, fill = tgroup)) +

  geom_bar(position = "fill") +

  theme(legend.position = "none")



layout <- matrix(c(1,1,2,2,3,3,3,3,4,5,6,7),3,4,byrow=TRUE)

multiplot(p1, p2,   p7, layout=layout)

p1 <- 1; p2 <- 1;   p7 <- 1

```


```{r fig.align = 'default', warning = FALSE, fig.cap ="Fig. 34", out.width="100%"}

allu_train <- train_group %>%

  group_by(tgroup, work, wday) %>% # jfk_trip

  count() %>%

  ungroup

  

alluvial(allu_train %>% select(-n),

         freq=allu_train$n, border=NA,

         col=ifelse(allu_train$tgroup == "fast", "red", "blue"),

         cex=0.75,

         hide = allu_train$n < 150,

         ordering = list(

           order(allu_train$tgroup=="fast"),

       #    NULL,

           NULL,

           NULL))

```

# Model, correlation

```{r  fig.align = 'default', warning = FALSE, fig.cap ="Fig. 35", out.width="100%"}

foo <- combine %>%

  mutate(date = date(ymd_hms(pickup_datetime))) %>%

  group_by(date, dset) %>%

  count() %>%

  ungroup()

foo %>%

  ggplot(aes(date, n/1e3, color = dset)) +

  geom_line(size = 1.5) +

  labs(x = "", y = "Kilo trips per day")

```

```{r fig.align = 'default', warning = FALSE, fig.cap ="Fig. 36", out.width="100%"}

pick_good <- combine %>%

  filter(pickup_longitude > -75 & pickup_longitude < -73) %>%

  filter(pickup_latitude > 40 & pickup_latitude < 42)

pick_good <- sample_n(pick_good, 5e3)



pick_good %>%

  ggplot(aes(pickup_longitude, pickup_latitude, color = dset)) +

  geom_point(size=0.1, alpha = 0.5) +

  coord_cartesian(xlim = c(-74.02,-73.77), ylim = c(40.63,40.84)) +

  facet_wrap(~ dset) +

  #guides(color = guide_legend(override.aes = list(alpha = 1, size = 4))) +

  theme(legend.position = "none")

```

# Modeling 

## Sample Model 1 Poisson (No store_and_fwd_flag, id  or vendor_id)

```{r message=FALSE, warning=FALSE}
attach(sub_train)
sample_model = glm(trip_duration ~ pickup_datetime:dropoff_datetime+pickup_latitude:pickup_longitude+dropoff_latitude:dropoff_longitude, family = poisson)

par(mfrow = c(2,3))
plot(sample_model,  
     pch  = 20,
     cex  = 2,
     col  = "grey")
abline(sample_model, lwd = 3, col = "darkorange")
halfnorm(hatvalues(sample_model))

summary(sample_model)
#confint(sample_model, level = 0.99)
tidy(sample_model) 
#augment(sample_model) 
glance(sample_model)
```


Breusch-Pagan Test. 

Cooks Distance
H0: Homoscedasticity. The errors have constant variance about the true model.
H1: Heteroscedasticity. The errors have non-constant variance about the true model.
Leverage, Outliers, Influence, coef Change

```{r message=FALSE, warning=FALSE}
cooks.distance(sample_model)[11] > 4 / length(cooks.distance(sample_model))
bptest(sample_model)
par(mfrow = c(2,3))
hist(resid(sample_model))

qqnorm(resid(sample_model), main = "Normal Q-Q Plot, sample_model", col = "darkgrey")
qqline(resid(sample_model), col = "dodgerblue", lwd = 2)

plot(log(fitted(sample_model)), log(resid(sample_model)), col = "grey", pch = 20,
     xlab = "Fitted", ylab = "Residuals", main = "Data from Model 1")
abline(h = 0, col = "darkorange", lwd = 2)

plot(which(hatvalues(sample_model) > 2 * mean(hatvalues(sample_model)), TRUE))

plot(rstandard(sample_model)[abs(rstandard(sample_model)) > 2])
cd_sample_model_add = cooks.distance(sample_model)
sum(cd_sample_model_add > 4 / length(cd_sample_model_add))


large_cd_train = cd_sample_model_add > 4 / length(cd_sample_model_add)
plot(cd_sample_model_add[large_cd_train])



coef(sample_model)
sample_model_add_fix = lm(trip_duration ~ dropoff_longitude,
                    data = train,
                    subset = cd_sample_model_add <= 4 / length(cd_sample_model_add))
coef(sample_model_add_fix)

#set.seed(42)
#shapiro.test(resid(sample_model))

```

```{r message=FALSE, warning=FALSE}
boxcox(sample_model, plotit = TRUE)
```

## Sample Model 2 Gaussian(No  id  or vendor_id)

```{r message=FALSE, warning=FALSE}
attach(sub_train)
sample_model2 = glm(trip_duration ~ pickup_datetime:dropoff_datetime+pickup_latitude:pickup_longitude+dropoff_latitude:dropoff_longitude+store_and_fwd_flag, family = gaussian)

par(mfrow = c(2,3))
plot(sample_model2,  
     pch  = 20,
     cex  = 2,
     col  = "grey")
abline(sample_model2, lwd = 3, col = "darkorange")
halfnorm(hatvalues(sample_model2))

summary(sample_model2)
#confint(sample_model2, level = 0.99)
tidy(sample_model2) 
#augment(sample_model) 
glance(sample_model2)
```

Breusch-Pagan Test. 

Cooks Distance
H0: Homoscedasticity. The errors have constant variance about the true model.
H1: Heteroscedasticity. The errors have non-constant variance about the true model.
Leverage, Outliers, Influence, coef Change

```{r message=FALSE, warning=FALSE}
cooks.distance(sample_model2)[11] > 4 / length(cooks.distance(sample_model2))
bptest(sample_model2)
par(mfrow = c(2,3))
hist(resid(sample_model2))

qqnorm(resid(sample_model2), main = "Normal Q-Q Plot, sample_model", col = "darkgrey")
qqline(resid(sample_model2), col = "dodgerblue", lwd = 2)

plot(log(fitted(sample_model2)), log(resid(sample_model2)), col = "grey", pch = 20,
     xlab = "Fitted", ylab = "Residuals", main = "Data from Model 2")
abline(h = 0, col = "darkorange", lwd = 2)

plot(which(hatvalues(sample_model2) > 2 * mean(hatvalues(sample_model2)), TRUE))

plot(rstandard(sample_model2)[abs(rstandard(sample_model2)) > 2])
cd_sample_model2_add = cooks.distance(sample_model2)
sum(cd_sample_model2_add > 4 / length(cd_sample_model2_add))


large_cd_train = cd_sample_model2_add > 4 / length(cd_sample_model2_add)
plot(cd_sample_model2_add[large_cd_train])



coef(sample_model2)
sample_model2_add_fix = lm(trip_duration ~ dropoff_longitude,
                    data = train,
                    subset = cd_sample_model2_add <= 4 / length(cd_sample_model2_add))
coef(sample_model2_add_fix)

#set.seed(42)
#shapiro.test(resid(sample_model))

```

```{r message=FALSE, warning=FALSE}
boxcox(sample_model2, plotit = TRUE)
```

## Sample Model 3 Negative Binomial  (No  id)

```{r message=FALSE, warning=FALSE}
attach(sub_train)
sample_model3 = lm(trip_duration ~ pickup_datetime:dropoff_datetime+pickup_latitude:pickup_longitude+dropoff_latitude:dropoff_longitude+store_and_fwd_flag+vendor_id, family = negative.binomial(1))

par(mfrow = c(2,3))
plot(sample_model3,  
     pch  = 20,
     cex  = 2,
     col  = "grey")
abline(sample_model3, lwd = 3, col = "darkorange")
halfnorm(hatvalues(sample_model3))

summary(sample_model3)
#confint(sample_model3, level = 0.99)
tidy(sample_model3) 
#augment(sample_model) 
glance(sample_model3)
```

Breusch-Pagan Test. 

Cooks Distance
H0: Homoscedasticity. The errors have constant variance about the true model.
H1: Heteroscedasticity. The errors have non-constant variance about the true model.
Leverage, Outliers, Influence, coef Change

```{r message=FALSE, warning=FALSE}
cooks.distance(sample_model3)[11] > 4 / length(cooks.distance(sample_model3))
bptest(sample_model3)
par(mfrow = c(2,3))
hist(resid(sample_model3))

qqnorm(resid(sample_model3), main = "Normal Q-Q Plot, sample_model", col = "darkgrey")
qqline(resid(sample_model3), col = "dodgerblue", lwd = 2)

plot(log(fitted(sample_model3)), log(resid(sample_model3)), col = "grey", pch = 20,
     xlab = "Fitted", ylab = "Residuals", main = "Data from Model 3")
abline(h = 0, col = "darkorange", lwd = 2)

plot(which(hatvalues(sample_model3) > 2 * mean(hatvalues(sample_model3)), TRUE))

plot(rstandard(sample_model3)[abs(rstandard(sample_model3)) > 2])
cd_sample_model3_add = cooks.distance(sample_model3)
sum(cd_sample_model3_add > 4 / length(cd_sample_model3_add))


large_cd_train = cd_sample_model3_add > 4 / length(cd_sample_model3_add)
plot(cd_sample_model3_add[large_cd_train])



coef(sample_model3)
sample_model3_add_fix = lm(trip_duration ~ dropoff_longitude,
                    data = train,
                    subset = cd_sample_model3_add <= 4 / length(cd_sample_model3_add))
coef(sample_model3_add_fix)

#set.seed(42)
#shapiro.test(resid(sample_model))

```

```{r message=FALSE, warning=FALSE}
boxcox(sample_model3, plotit = TRUE)
```

```{r echo=FALSE,message=FALSE,warning=FALSE}
m1AIC <- AIC(sample_model)
m1BIC <- BIC(sample_model)
m2AIC <- AIC(sample_model2)
m2BIC <- BIC(sample_model2)
m3AIC <- AIC(sample_model3)
m3BIC <- BIC(sample_model3)


AIC <- list(m1AIC, m2AIC, m3AIC)
BIC <- list(m1BIC, m2BIC, m3BIC)
kable(rbind(AIC, BIC), col.names = c("Model 1", "Model 2", "Model 3"))  %>% 
  kable_styling(full_width = T)
```

# CONCLUSION
With 3 models computed, we select the model with the lowest combination of AIC and BIC. From the table, we can see the model to pick is model 1

```{r echo=FALSE, message=FALSE, warning=FALSE}
eval_p<-predict(sample_model3,sub_train, type = "response")
write.csv(eval_p,"predicted_eval_values.csv")
```

Model 1 showed the best result. We can observe its performance by plotting the datasets Vendor_ID values against the predicted values. 

```{r echo=FALSE, message=FALSE, warning=FALSE}
par(mfrow = c(1,3))
train_p<-predict(sample_model,sub_train, type = "response")
plot(train_p,sub_train$trip_duration,main = "Model 1")
train_p<-predict(sample_model2,sub_train, type = "response")
plot(train_p,sub_train$trip_duration,main = "Model 2")
train_p<-predict(sample_model3,sub_train, type = "response")
plot(train_p,sub_train$trip_duration,main = "Model 3")
```


# APPENDIX

**Code used in analysis**
```{r, ref.label=knitr::all_labels(),echo=TRUE,eval=FALSE}

```


# References:
1. Traffic congestion costs metro economy $20 billion a year: study. Crain’s New York Business. https://www.crainsnewyork.com/article/20180118/POLITICS/180119895/traffic-congestion-costs-metro-economy-20-billion-a-year-study. Published January 18, 2018. Accessed November 13, 2019.

2. FDNY: Traffic — Not Bike Lanes — is to Blame for Increased Response Times. Streetsblog New York City. https://nyc.streetsblog.org/2019/09/19/fdny-traffic-not-bike-lanes-is-to-blame-for-increase d-response-times/. Published September 19, 2019. Accessed November 13, 2019.

3. Skandul, E. How New York City taxis can get ahead of Uber and Lyft. CSNY. https://www.cityandstateny.com/articles/opinion/commentary/how-new-york-city-taxis-can-get-ahead-of-uber-and-lyft.html. Published October 17, 2019. Accessed November 13, 2019.

4. Sanders A. De Blasio struggles to find new Taxi and Limousine commissioner after first pick’s disastrous performance at Council Hearing. nydailynews.com. https://www.nydailynews.com/news/politics/ny-city-council-de-blasio-official-tlc-commissioner-jeff-lynch-20191003-cfx27yihafcebj4e62wytsprpu-story.html. Published October 3, 2019. Accessed November 13, 2019.

5. New York City Taxi Trip Duration | Kaggle. Kaggle.com. https://www.kaggle.com/c/nyc-taxi-trip-duration/data#. Published 2017. Accessed November 13, 2019.

6. About TLC - TLC. Nyc.gov. https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page. Published 2019. Accessed November 13, 2019.

7. Use holidays as a feature | Kaggle. Kaggle.com. https://www.kaggle.com/c/nyc-taxi-trip-duration/discussion/37192#latest-572412. Published 2017. Accessed November 13, 2019.