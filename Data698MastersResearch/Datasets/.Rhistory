setwd('C:\\Users\\apagan\\OneDrive - BizoIT, Inc\\Desktop\\GitHub1\\CUNYSPS\\Data698\\Datasets')
#df <- read.csv("CTG.csv")
df<-nn# Convert the data.frame to a matrix
data <- as.matrix(df)
# Remove variable names
dimnames(data) <- NULL
# Convert target variable values from 1, 2, 3 to 0, 1, 2
#data[, 22] <- as.numeric(data[, 22]) - 1
data[, 7] <- as.numeric(data[, 7]) - 1 # Broadcasting
#The data has to be split into a training and a test set. This can be done through indexing, creating two indices, 1 and 2. The test data is set to comprise 30% of the 2,126 samples.
# Split for train and test data
set.seed(123)
indx <- sample(2,
nrow(data),
replace = TRUE,
prob = c(0.7, 0.3)) # Makes index with values 1 and 2
x_train <- data[indx == 1, 1:6] # Take rows with index = 1
x_test <- data[indx == 2, 1:6]
#y_test_actual <- data[indx == 2, 22]
y_test_actual <- data[indx == 2, 7]
y_train <-to_categorical(data[indx == 1, 7])
y_test <- to_categorical(data[indx == 2, 7])
# Creating the model
model <- keras_model_sequential()
model %>%
layer_dense(units = 7,
kernel_regularizer = regularizer_l2(0.001),
activation = "relu",
input_shape = c(7)) %>%
layer_dropout(rate = 0.2) %>%
layer_dense(units = 12,
kernel_regularizer = regularizer_l2(0.001),
activation = "relu") %>%
layer_dense(units = 3,
activation = "softmax")
summary(model)
# Compiling the model
model %>% compile(loss = "categorical_crossentropy",
optimizer = "adam",
metrics = c("accuracy"))
memory.limit(size=60000)
#devtools::install_github("rstudio/tensorflow")
#devtools::install_github("rstudio/keras")
history <- model %>%
fit(x_train,
y_train,
epoch = 20,
batch_size = 64,
validation_split = 0.2)
View(x_train)
View(y_train)
plot(x_train)
View(x_train)
plot(x_train$V6)
plot(x_train[1])
x_train[1]
x_train[,30]
x_train[,1]
plot(x_train[,1])
mean_train <- apply(x_train,
2,
mean)
std_train <- apply(x_train,
2,
sd)
x_train <- scale(x_train,
center = mean_train,
scale = std_train)
x_test <- scale(x_test,
center = mean_train,
scale = std_train)
# Creating the model
model <- keras_model_sequential()
model %>%
layer_dense(units = 7,
kernel_regularizer = regularizer_l2(0.001),
activation = "relu",
input_shape = c(7)) %>%
layer_dropout(rate = 0.2) %>%
layer_dense(units = 12,
kernel_regularizer = regularizer_l2(0.001),
activation = "relu") %>%
layer_dense(units = 3,
activation = "softmax")
summary(model)
# Compiling the model
model %>% compile(loss = "categorical_crossentropy",
optimizer = "adam",
metrics = c("accuracy"))
#memory.limit(size=60000)
#devtools::install_github("rstudio/tensorflow")
#devtools::install_github("rstudio/keras")
history <- model %>%
fit(x_train,
y_train,
epoch = 20,
batch_size = 64,
validation_split = 0.2)
View(x_train)
View(y_train)
#memory.limit(size=60000)
install_tensorflow(gpu=TRUE)
knitr::opts_chunk$set(
echo = FALSE,
message = FALSE,
warning = FALSE
)
rm(list=ls())
list.of.packages <- c("alluvial","caret","caret","corrplot","corrplot","data.table","dplyr","faraway","forcats","geosphere","ggplot2","ggplot2","ggplot2","grid","gridExtra","jtools","kableExtra","knitr","leaflet","leaflet.extras","leaps","lubridate","maps","MASS","mice","naniar","pander","patchwork","prettydoc","pROC","psych","RColorBrewer","readr","reshape2","scales","stringr","tibble","tidyr","tidyverse","xgboost","widgetframe","Rcpp","mlbench","fpp2","mlr","jsonlite","devtools","sparklyr","SparkR","readtext","magrittr","simmer","quanteda","tidytext","tm","SnowballC","text2vec","purrr","topicmodels","RMySQL","plotly","GGally","corrplot","imputeTS","keras","tensorflow")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages, dependencies=TRUE)
#knitr::opts_chunk$set(echo = TRUE)
require(knitr)
library(ggplot2)
library(tidyr)
library(MASS)
library(psych)
library(kableExtra)
library(dplyr)
library(faraway)
library(gridExtra)
library(reshape2)
library(leaps)
library(pROC)
library(caret)
library(pROC)
library(mlbench)
library(e1071)
library(fpp2)
library(mlr)
library(recommenderlab)
library(jsonlite)
library(stringr)
library(devtools)
library(sparklyr)
library(readtext)
library(simmer)
library(quanteda)
library(tidytext)
library(tm)
library(purrr)
library(topicmodels)
library(RMySQL)
library(plotly)
library(GGally)
library(corrplot)
library(imputeTS)
library(car)
library(rpart)
library(keras)
setwd('C:\\Users\\apagan\\OneDrive - BizoIT, Inc\\Desktop\\GitHub1\\CUNYSPS\\Data698\\Datasets')
#df <- read.csv("CTG.csv")
df<-nn# Convert the data.frame to a matrix
d1<- as.data.frame(read.csv('TestQuery.csv', header = TRUE,quote = ""))
d1<-rename(d1, DateTime=names(d1[1]))
cnames<-c('AlertName','AlertDescription','Severity','Priority','DateTime','ManagedEntityGuid')
d2<- as.data.frame(read.csv('TestQuery3.csv',header= FALSE, col.names = cnames, quote = "\"", sep=","))
joineddata<-right_join(d1, d2,  by = c("DateTime","ManagedEntityGuid"))
joineddata<-subset(joineddata,!is.na(SampleValue))%>%
subset(select=c(-AlertName.x,-Severity.x))%>%
rename(AlertName = AlertName.y, Severity = Severity.y)%>%
mutate(ServerName = case_when
((ManagedEntityGuid == '2A909362-BE1E-F148-835C-96787AE2775E') ~ 'Server1',
(ManagedEntityGuid == '6EA459BD-0616-71F6-FC4A-7989A2DCF9FD') ~ 'Server2',
(ManagedEntityGuid == 'A1A8A538-8B75-B8F5-5F44-7159F192F602') ~ 'Server3',
(ManagedEntityGuid == 'AF487CE3-8C62-2C7A-F748-9241D73F0403') ~ 'Server4',
TRUE ~ 'Server5'))%>%
mutate(Ticket = case_when
((Severity == 2) ~ 1,
TRUE ~ 0))
sdata<-joineddata%>%subset(select=c(-Objectname, -AlertDescription))%>%
group_by(DateTime, ServerName, CounterName, AlertName)%>%
mutate(row_id=1:n()) %>% ungroup() %>%
spread(CounterName, SampleValue)%>%
subset(select=c(-row_id,-Priority))
nonats<-na_kalman(sdata)
#Remove highly correllated Ops master* column, replace with avg
df <- nonats %>% select(starts_with("Op Master"))
#df<-names(df)
nonats<-nonats%>%mutate(MasterAvg=rowMeans(cbind(nonats[names(df)])))
nonats<-nonats%>%select(!c(names(df)))
#remove any columns with NA
nonats2<-nonats%>%
select(where(~!any(is.na(.))))
#replace NA with 0
nonats3<-nonats%>%na.replace()
nn<-nonats2[1:2000,c(7:ncol(nonats2))]
setwd('C:\\Users\\apagan\\OneDrive - BizoIT, Inc\\Desktop\\GitHub1\\CUNYSPS\\Data698\\Datasets')
#df <- read.csv("CTG.csv")
df<-nn# Convert the data.frame to a matrix
data <- as.matrix(df)
# Remove variable names
dimnames(data) <- NULL
# Convert target variable values from 1, 2, 3 to 0, 1, 2
#data[, 22] <- as.numeric(data[, 22]) - 1
data[, 7] <- as.numeric(data[, 7]) - 1 # Broadcasting
#The data has to be split into a training and a test set. This can be done through indexing, creating two indices, 1 and 2. The test data is set to comprise 30% of the 2,126 samples.
# Split for train and test data
set.seed(123)
indx <- sample(2,
nrow(data),
replace = TRUE,
prob = c(0.7, 0.3)) # Makes index with values 1 and 2
x_train <- data[indx == 1, 1:6] # Take rows with index = 1
x_test <- data[indx == 2, 1:6]
#A separate computer variable is created to hold the ground-truth (actual) feature values of the test set for later use.
#y_test_actual <- data[indx == 2, 22]
y_test_actual <- data[indx == 2, 7]
#The feature variables of the training and test sets can be one-hot-encoded using the Keras function to_categorical().
# Using similar indices to correspond to the training and test set
#y_train <-to_categorical(data[indx == 1, 22])
#y_test <- to_categorical(data[indx == 2, 22])
y_train <-to_categorical(data[indx == 1, 7])
# Using similar indices to correspond to the training and test set
#y_train <-to_categorical(data[indx == 1, 22])
#y_test <- to_categorical(data[indx == 2, 22])
y_train <-to_categorical(data[indx == 1, 7])
#memory.limit(size=60000)
install_tensorflow()
knitr::opts_chunk$set(
echo = FALSE,
message = FALSE,
warning = FALSE
)
rm(list=ls())
list.of.packages <- c("alluvial","caret","caret","corrplot","corrplot","data.table","dplyr","faraway","forcats","geosphere","ggplot2","ggplot2","ggplot2","grid","gridExtra","jtools","kableExtra","knitr","leaflet","leaflet.extras","leaps","lubridate","maps","MASS","mice","naniar","pander","patchwork","prettydoc","pROC","psych","RColorBrewer","readr","reshape2","scales","stringr","tibble","tidyr","tidyverse","xgboost","widgetframe","Rcpp","mlbench","fpp2","mlr","jsonlite","devtools","sparklyr","SparkR","readtext","magrittr","simmer","quanteda","tidytext","tm","SnowballC","text2vec","purrr","topicmodels","RMySQL","plotly","GGally","corrplot","imputeTS","keras","tensorflow")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages, dependencies=TRUE)
#knitr::opts_chunk$set(echo = TRUE)
require(knitr)
library(ggplot2)
library(tidyr)
library(MASS)
library(psych)
library(kableExtra)
library(dplyr)
library(faraway)
library(gridExtra)
library(reshape2)
library(leaps)
library(pROC)
library(caret)
library(pROC)
library(mlbench)
library(e1071)
library(fpp2)
library(mlr)
library(recommenderlab)
library(jsonlite)
library(stringr)
library(devtools)
library(sparklyr)
library(readtext)
library(simmer)
library(quanteda)
library(tidytext)
library(tm)
library(purrr)
library(topicmodels)
library(RMySQL)
library(plotly)
library(GGally)
library(corrplot)
library(imputeTS)
library(car)
library(rpart)
library(keras)
install(reticulate)
install(reticulate)
library(reticulate)
library(keras)
library(tensorflow)
if(length(new.packages)) install.packages(new.packages, dependencies=TRUE)
knitr::opts_chunk$set(
echo = FALSE,
message = FALSE,
warning = FALSE
)
rm(list=ls())
list.of.packages <- c("alluvial","caret","caret","corrplot","corrplot","data.table","dplyr","faraway","forcats","geosphere","ggplot2","ggplot2","ggplot2","grid","gridExtra","jtools","kableExtra","knitr","leaflet","leaflet.extras","leaps","lubridate","maps","MASS","mice","naniar","pander","patchwork","prettydoc","pROC","psych","RColorBrewer","readr","reshape2","scales","stringr","tibble","tidyr","tidyverse","xgboost","widgetframe","Rcpp","mlbench","fpp2","mlr","jsonlite","devtools","sparklyr","SparkR","readtext","magrittr","simmer","quanteda","tidytext","tm","SnowballC","text2vec","purrr","topicmodels","RMySQL","plotly","GGally","corrplot","imputeTS","keras","tensorflow")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages, dependencies=TRUE)
#knitr::opts_chunk$set(echo = TRUE)
require(knitr)
library(ggplot2)
library(tidyr)
library(MASS)
library(psych)
library(kableExtra)
library(dplyr)
library(faraway)
library(gridExtra)
library(reshape2)
library(leaps)
library(pROC)
library(caret)
library(pROC)
library(mlbench)
library(e1071)
library(fpp2)
library(mlr)
library(recommenderlab)
library(jsonlite)
library(stringr)
library(devtools)
library(sparklyr)
library(readtext)
library(simmer)
library(quanteda)
library(tidytext)
library(tm)
library(purrr)
library(topicmodels)
library(RMySQL)
library(plotly)
library(GGally)
library(corrplot)
library(imputeTS)
library(car)
library(rpart)
library(keras)
#memory.limit(size=60000)
#install_tensorflow(gpu=TRUE)
devtools::install_github("rstudio/tensorflow")
devtools::install_github("rstudio/keras")
#memory.limit(size=60000)
#install_tensorflow(gpu=TRUE)
#devtools::install_github("rstudio/tensorflow")
#devtools::install_github("rstudio/keras")
history <- model %>%
fit(x_train,
y_train,
epoch = 20,
batch_size = 64,
validation_split = 0.2)
knitr::opts_chunk$set(
echo = FALSE,
message = FALSE,
warning = FALSE
)
rm(list=ls())
list.of.packages <- c("alluvial","caret","caret","corrplot","corrplot","data.table","dplyr","faraway","forcats","geosphere","ggplot2","ggplot2","ggplot2","grid","gridExtra","jtools","kableExtra","knitr","leaflet","leaflet.extras","leaps","lubridate","maps","MASS","mice","naniar","pander","patchwork","prettydoc","pROC","psych","RColorBrewer","readr","reshape2","scales","stringr","tibble","tidyr","tidyverse","xgboost","widgetframe","Rcpp","mlbench","fpp2","mlr","jsonlite","devtools","sparklyr","SparkR","readtext","magrittr","simmer","quanteda","tidytext","tm","SnowballC","text2vec","purrr","topicmodels","RMySQL","plotly","GGally","corrplot","imputeTS","keras","tensorflow")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages, dependencies=TRUE)
#knitr::opts_chunk$set(echo = TRUE)
require(knitr)
library(ggplot2)
library(tidyr)
library(MASS)
library(psych)
library(kableExtra)
library(dplyr)
library(faraway)
library(gridExtra)
library(reshape2)
library(leaps)
library(pROC)
library(caret)
library(pROC)
library(mlbench)
library(e1071)
library(fpp2)
library(mlr)
library(recommenderlab)
library(jsonlite)
library(stringr)
library(devtools)
library(sparklyr)
library(readtext)
library(simmer)
library(quanteda)
library(tidytext)
library(tm)
library(purrr)
library(topicmodels)
library(RMySQL)
library(plotly)
library(GGally)
library(corrplot)
library(imputeTS)
library(car)
library(rpart)
library(keras)
d1<- as.data.frame(read.csv('TestQuery.csv', header = TRUE,quote = ""))
d1<-rename(d1, DateTime=names(d1[1]))
cnames<-c('AlertName','AlertDescription','Severity','Priority','DateTime','ManagedEntityGuid')
d2<- as.data.frame(read.csv('TestQuery3.csv',header= FALSE, col.names = cnames, quote = "\"", sep=","))
joineddata<-right_join(d1, d2,  by = c("DateTime","ManagedEntityGuid"))
joineddata<-subset(joineddata,!is.na(SampleValue))%>%
subset(select=c(-AlertName.x,-Severity.x))%>%
rename(AlertName = AlertName.y, Severity = Severity.y)%>%
mutate(ServerName = case_when
((ManagedEntityGuid == '2A909362-BE1E-F148-835C-96787AE2775E') ~ 'Server1',
(ManagedEntityGuid == '6EA459BD-0616-71F6-FC4A-7989A2DCF9FD') ~ 'Server2',
(ManagedEntityGuid == 'A1A8A538-8B75-B8F5-5F44-7159F192F602') ~ 'Server3',
(ManagedEntityGuid == 'AF487CE3-8C62-2C7A-F748-9241D73F0403') ~ 'Server4',
TRUE ~ 'Server5'))%>%
mutate(Ticket = case_when
((Severity == 2) ~ 1,
TRUE ~ 0))
sdata<-joineddata%>%subset(select=c(-Objectname, -AlertDescription))%>%
group_by(DateTime, ServerName, CounterName, AlertName)%>%
mutate(row_id=1:n()) %>% ungroup() %>%
spread(CounterName, SampleValue)%>%
subset(select=c(-row_id,-Priority))
nonats<-na_kalman(sdata)
#Remove highly correllated Ops master* column, replace with avg
df <- nonats %>% select(starts_with("Op Master"))
#df<-names(df)
nonats<-nonats%>%mutate(MasterAvg=rowMeans(cbind(nonats[names(df)])))
nonats<-nonats%>%select(!c(names(df)))
#remove any columns with NA
nonats2<-nonats%>%
select(where(~!any(is.na(.))))
#replace NA with 0
nonats3<-nonats%>%na.replace()
nn<-nonats2[1:2000,c(7:ncol(nonats2))]
setwd('C:\\Users\\apagan\\OneDrive - BizoIT, Inc\\Desktop\\GitHub1\\CUNYSPS\\Data698\\Datasets')
#df <- read.csv("CTG.csv")
df<-nn# Convert the data.frame to a matrix
data <- as.matrix(df)
# Remove variable names
dimnames(data) <- NULL
# Convert target variable values from 1, 2, 3 to 0, 1, 2
#data[, 22] <- as.numeric(data[, 22]) - 1
data[, 7] <- as.numeric(data[, 7]) - 1 # Broadcasting
#The data has to be split into a training and a test set. This can be done through indexing, creating two indices, 1 and 2. The test data is set to comprise 30% of the 2,126 samples.
# Split for train and test data
set.seed(123)
indx <- sample(2,
nrow(data),
replace = TRUE,
prob = c(0.7, 0.3)) # Makes index with values 1 and 2
x_train <- data[indx == 1, 1:6] # Take rows with index = 1
x_test <- data[indx == 2, 1:6]
#A separate computer variable is created to hold the ground-truth (actual) feature values of the test set for later use.
#y_test_actual <- data[indx == 2, 22]
y_test_actual <- data[indx == 2, 7]
#The feature variables of the training and test sets can be one-hot-encoded using the Keras function to_categorical().
# Using similar indices to correspond to the training and test set
#y_train <-to_categorical(data[indx == 1, 22])
#y_test <- to_categorical(data[indx == 2, 22])
y_train <-to_categorical(data[indx == 1, 7])
??to_categorical
# Using similar indices to correspond to the training and test set
#y_train <-to_categorical(data[indx == 1, 22])
#y_test <- to_categorical(data[indx == 2, 22])
y_train <-keras::to_categorical(data[indx == 1, 7])
??reticulate
install.packages("reticulate")
# Using similar indices to correspond to the training and test set
#y_train <-to_categorical(data[indx == 1, 22])
#y_test <- to_categorical(data[indx == 2, 22])
y_train <-keras::to_categorical(data[indx == 1, 7])
library(reticulate)
install.packages("reticulate")
knitr::opts_chunk$set(
echo = FALSE,
message = FALSE,
warning = FALSE
)
rm(list=ls())
list.of.packages <- c("alluvial","caret","caret","corrplot","corrplot","data.table","dplyr","faraway","forcats","geosphere","ggplot2","ggplot2","ggplot2","grid","gridExtra","jtools","kableExtra","knitr","leaflet","leaflet.extras","leaps","lubridate","maps","MASS","mice","naniar","pander","patchwork","prettydoc","pROC","psych","RColorBrewer","readr","reshape2","scales","stringr","tibble","tidyr","tidyverse","xgboost","widgetframe","Rcpp","mlbench","fpp2","mlr","jsonlite","devtools","sparklyr","SparkR","readtext","magrittr","simmer","quanteda","tidytext","tm","SnowballC","text2vec","purrr","topicmodels","RMySQL","plotly","GGally","corrplot","imputeTS","keras","tensorflow","reticulate")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages, dependencies=TRUE)
#knitr::opts_chunk$set(echo = TRUE)
require(knitr)
library(ggplot2)
library(tidyr)
library(MASS)
library(psych)
library(kableExtra)
library(dplyr)
library(faraway)
library(gridExtra)
library(reshape2)
library(leaps)
library(pROC)
library(caret)
library(pROC)
library(mlbench)
library(e1071)
library(fpp2)
library(mlr)
library(recommenderlab)
library(jsonlite)
library(stringr)
library(devtools)
library(sparklyr)
library(readtext)
library(simmer)
library(quanteda)
library(tidytext)
library(tm)
library(purrr)
library(topicmodels)
library(RMySQL)
library(plotly)
library(GGally)
library(corrplot)
library(imputeTS)
library(car)
library(rpart)
library(keras)
remove.packages(keras)
remove.packages('keras')
remove.packages(tensorflow)
install.packages(kears)
install.packages(keras)
library(tensorflow)
library(naniar)
library(reticulate)
